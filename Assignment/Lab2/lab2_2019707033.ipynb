{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Lab2 2019707033 김태윤\r\n",
    "\r\n",
    " \t\r\n",
    "\r\n",
    "Lab assignment #2:\r\n",
    "\r\n",
    "\r\n",
    "1. 수업 시간에 보았던 예제를 참고하여 Indeed Web page 에서 채용 정보 검색 후 모든 페이지에 대해 결과 print 하기.\r\n",
    "\r\n",
    "   (검색어=\"data scientist\", 지역=\"서울특별시\")\r\n",
    "\r\n",
    "\r\n",
    "2. 미래에 취업 희망하는 회사를 검색해서 (기업리뷰) 그 회사의 리뷰 내용을 프린트 하기\r\n",
    "\r\n",
    "   (만약 한 페이지가 넘으면 모든 페이지에 대해 검색하되 상한선은 20 개 정도로 정함)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import requests\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import math\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from tabulate import tabulate"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- - -\r\n",
    "# 1. 수업시간에 보았던 예제를 참고하여 Indeed Web page에서 채용 정보 검색 후 모든 페이지에 대해 결과 print 하기\r\n",
    "                (검색어=\"data scientist\", 지역=\"서울특별시\")"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 검색 결과 페이지수 탐색\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 검색 결과 첫 페이지 가져오기\r\n",
    "url = 'https://kr.indeed.com/jobs?q=data+scientist&l=%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C&sort=date&start=0'\r\n",
    "link = requests.get(url)\r\n",
    "soup = BeautifulSoup(link.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# 페이지 수 계산\r\n",
    "items = int(soup.find('div', id=\"searchCountPages\").text[29:-1])\r\n",
    "pages_items = math.ceil(items/15)\r\n",
    "print(\"검색 결과 수 : \", items)\r\n",
    "print(\"검색 결과 페이지 수 : \", pages_items)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 모든 페이지 결과 종합"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "list_result = []\r\n",
    "for page in range(pages_items):\r\n",
    "    # 메뉴 테스트\r\n",
    "    url = \"https://kr.indeed.com/jobs?q=data+scientist&l=%EC%84%9C%EC%9A%B8%ED%8A%B9%EB%B3%84%EC%8B%9C&sort=date&start=\"+str(page*10)\r\n",
    "    link = requests.get(url)\r\n",
    "    soup = BeautifulSoup(link.text, \"html.parser\")\r\n",
    "    \r\n",
    "    job_elems = soup.select(\".resultContent\")\r\n",
    "\r\n",
    "    count_item = 0\r\n",
    "    for x in job_elems:\r\n",
    "        title = x.find(\"h2\")\r\n",
    "        company = x.find(\"span\", class_=\"companyName\")\r\n",
    "        location = x.find(\"div\", class_=\"companyLocation\")\r\n",
    "\r\n",
    "        if None in (title, company, location):\r\n",
    "            continue\r\n",
    "\r\n",
    "        list_result.append(title.text.strip())\r\n",
    "        list_result.append(company.text.strip())\r\n",
    "        list_result.append(location.text.strip())\r\n",
    "\r\n",
    "        count_item+=1\r\n",
    "    \r\n",
    "    print(str(page+1)+\" page Checked, \"+str(count_item)+\" found.\")\r\n",
    "\r\n",
    "print()\r\n",
    "list_result = np.reshape(list_result, (-1, 3))\r\n",
    "print(tabulate(list_result, headers = [\"Title\", \"Company\", \"Location\"]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- - -\r\n",
    "# 2. 미래에 취업 희망하는 회사를 검색해서 (기업리뷰) 그 회사의 리뷰 내용을 프린트 하기\r\n",
    "\r\n",
    "   (만약 한 페이지가 넘으면 모든 페이지에 대해 검색하되 상한선은 20 개 정도로 정함)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "# 검색 결과 첫 페이지 가져오기\r\n",
    "url = 'https://kr.indeed.com/cmp/Spacex/reviews?fcountry=ALL&start=0'\r\n",
    "link = requests.get(url)\r\n",
    "soup = BeautifulSoup(link.text, 'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# 페이지 수 계산\r\n",
    "reviews = int(soup.find('div', \"css-r228jg eu4oa1w0\").text)\r\n",
    "pages_reviews = math.ceil(reviews/20)\r\n",
    "print(\"검색 결과 수 : \", reviews)\r\n",
    "print(\"검색 결과 페이지 수 : \", pages_reviews)\r\n",
    "if pages_reviews > 20:\r\n",
    "    pages_reviews = 20\r\n",
    "print(\"수집할 페이지 수 \", pages_reviews)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "검색 결과 수 :  546\n",
      "검색 결과 페이지 수 :  28\n",
      "수집할 페이지 수  20\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}